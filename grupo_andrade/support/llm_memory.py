from langchain_openai import ChatOpenAI  
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder  
from langchain_core.runnables import RunnablePassthrough, RunnableWithMessageHistory
from langchain_core.output_parsers import StrOutputParser  
from langchain_community.chat_message_histories import SQLChatMessageHistory  
from dotenv import load_dotenv
import os

load_dotenv()

sistema = """
Voc√™ √© Jasmine, a assistente virtual do Grupo Andrade. Seja direta, amig√°vel e extremamente concisa 
(no m√°ximo 3 frases por resposta). 

üìå Regras essenciais:
1. Sempre seja humano
2. Responda APENAS com o contexto fornecido 
3. Seja espec√≠fica sobre prazos, documentos e valores quando perguntado
4. use emojis nas respostas a cada duas resposta.
5. use informa√ßao de  resultados "resposta_do_agente_para_LLM" para melhor esclarecimento de ferramentas 

contexto de ferramentas:
{contexto_ferramentas}
Contexto_retriver:
{contexto_retriver}
---------------------
"""

prompt = ChatPromptTemplate.from_messages([("system", sistema),
                                           MessagesPlaceholder(variable_name='history'),
                                            ("human", "{input}")])

# persistir todas as conversas baseadas em sess√£o do usu√°rio em um banco de dados SQL  
def get_session_history_db(session_id):  
    return SQLChatMessageHistory(session_id, connection=os.environ.get("DATABASE_URL_MEMORY", "sqlite:///memory_llm.db")) + f'?options=-c%20search_path=memory_llm'

# crie uma fun√ß√£o de janela de buffer de mem√≥ria para retornar as √∫ltimas K conversas  
def memory_window(messages, k=30):  
    return messages[-(k+1):]

def conversa_memoria():
# crie uma cadeia LLM simples que usa apenas as √∫ltimas K conversas  
    chatgpt = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

    llm_chain = (RunnablePassthrough.assign(history=lambda x: memory_window(x["history"]))  
                | prompt  
                | chatgpt  
                | StrOutputParser()) 

    # crie uma cadeia de conversa√ß√£o para lidar com o hist√≥rico baseado em sess√£o.  
    conv_chain = RunnableWithMessageHistory(
        llm_chain,
        get_session_history_db,
        input_messages_key="input",
        history_messages_key="history",
        )


    return conv_chain

